{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e241d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import HeteroData, Data\n",
    "from typing import List, Union\n",
    "\n",
    "def convert_single_graph(homogeneous_graph: Data, source_node_idx: int = 0, add_source_self_loop: bool = True) -> HeteroData:\n",
    "    \"\"\"\n",
    "    Convert a single homogeneous graph to a heterogeneous graph with two node types:\n",
    "    - 'source': News source node\n",
    "    - 'user': All other nodes\n",
    "    \n",
    "    And two edge types:\n",
    "    - ('source', 'to', 'user'): Edges from source to users\n",
    "    - ('user', 'to', 'user'): Edges between users\n",
    "    - ('source', 'to', 'source'): Self-loop for source node (optional)\n",
    "    \n",
    "    Args:\n",
    "        homogeneous_graph: A PyTorch Geometric Data object\n",
    "        source_node_idx: Index of the source node in the graph, default is 0\n",
    "        add_source_self_loop: Whether to add a self-loop to the source node, default is False\n",
    "        \n",
    "    Returns:\n",
    "        A HeteroData object\n",
    "    \"\"\"\n",
    "    hetero_graph = HeteroData()\n",
    "    \n",
    "    # Get total number of nodes\n",
    "    num_nodes = homogeneous_graph.num_nodes\n",
    "    \n",
    "    # Extract features for source node\n",
    "    source_features = homogeneous_graph.x[source_node_idx:source_node_idx+1]\n",
    "    \n",
    "    # Extract features for user nodes (all nodes except source)\n",
    "    user_indices = torch.cat([\n",
    "        torch.arange(0, source_node_idx), \n",
    "        torch.arange(source_node_idx + 1, num_nodes)\n",
    "    ])\n",
    "    user_features = homogeneous_graph.x[user_indices]\n",
    "    \n",
    "    # Add node features to the heterogeneous graph\n",
    "    hetero_graph['source'].x = source_features\n",
    "    hetero_graph['user'].x = user_features\n",
    "    \n",
    "    # Create a mapping from original node indices to new node indices\n",
    "    node_mapping = {}\n",
    "    node_mapping[source_node_idx] = ('source', 0)  # Source node maps to index 0 in 'source' type\n",
    "    \n",
    "    # Map all other nodes to 'user' type\n",
    "    user_counter = 0\n",
    "    for i in range(num_nodes):\n",
    "        if i != source_node_idx:\n",
    "            node_mapping[i] = ('user', user_counter)\n",
    "            user_counter += 1\n",
    "    \n",
    "    # Process edges\n",
    "    edge_index = homogeneous_graph.edge_index\n",
    "    \n",
    "    # Source-to-user edges and User-to-user edges\n",
    "    source_to_user_edges = []\n",
    "    user_to_user_edges = []\n",
    "    \n",
    "    for i in range(edge_index.shape[1]):\n",
    "        src, dst = edge_index[0, i].item(), edge_index[1, i].item()\n",
    "        \n",
    "        src_type, src_idx = node_mapping[src]\n",
    "        dst_type, dst_idx = node_mapping[dst]\n",
    "        \n",
    "        if src_type == 'source' and dst_type == 'user':\n",
    "            # Source to user edge\n",
    "            source_to_user_edges.append((src_idx, dst_idx))\n",
    "        elif src_type == 'user' and dst_type == 'user':\n",
    "            # User to user edge\n",
    "            user_to_user_edges.append((src_idx, dst_idx))\n",
    "        # We ignore user-to-source edges as mentioned in the requirements\n",
    "    \n",
    "    # Add edges to the heterogeneous graph\n",
    "    if source_to_user_edges:\n",
    "        src_indices, dst_indices = zip(*source_to_user_edges)\n",
    "        hetero_graph['source', 'to', 'user'].edge_index = torch.tensor(\n",
    "            [src_indices, dst_indices], dtype=torch.long\n",
    "        )\n",
    "        \n",
    "    \n",
    "    if user_to_user_edges:\n",
    "        src_indices, dst_indices = zip(*user_to_user_edges)\n",
    "        hetero_graph['user', 'to', 'user'].edge_index = torch.tensor(\n",
    "            [src_indices, dst_indices], dtype=torch.long\n",
    "        )\n",
    "    \n",
    "    # Add self-loop to source node if requested\n",
    "    if add_source_self_loop:\n",
    "        hetero_graph['source', 'to', 'source'].edge_index = torch.tensor(\n",
    "            [[0], [0]], dtype=torch.long\n",
    "        )\n",
    "    \n",
    "    # Copy graph-level targets if they exist\n",
    "    if hasattr(homogeneous_graph, 'y'):\n",
    "        hetero_graph['source'].y = homogeneous_graph.y\n",
    "    \n",
    "    return hetero_graph\n",
    "\n",
    "def convert_to_heterogeneous(homogeneous_dataset, source_node_idx=0, add_source_self_loop=True):\n",
    "    \"\"\"\n",
    "    Convert a homogeneous UPFD dataset to a heterogeneous dataset.\n",
    "    \n",
    "    Args:\n",
    "        homogeneous_dataset: A PyTorch Geometric UPFD dataset\n",
    "        source_node_idx: Index of the source node in each graph, default is 0\n",
    "        add_source_self_loop: Whether to add a self-loop to the source node, default is False\n",
    "        \n",
    "    Returns:\n",
    "        A list of HeteroData objects\n",
    "    \"\"\"\n",
    "    # Simply apply convert_single_graph to each graph in the dataset\n",
    "    hetero_dataset = [\n",
    "        convert_single_graph(graph, source_node_idx, add_source_self_loop) \n",
    "        for graph in homogeneous_dataset\n",
    "    ]\n",
    "    \n",
    "    return hetero_dataset\n",
    "\n",
    "def get_edge_type(edge_index, source_indices=[0]):\n",
    "    \"\"\"\n",
    "    Generate edge type tensor based on source node indices.\n",
    "    \n",
    "    This function creates a tensor of edge types by assigning different types to edges\n",
    "    based on whether the source node is in the specified list of source indices.\n",
    "    \n",
    "    Args:\n",
    "        edge_index (torch.Tensor): The edge index tensor of shape [2, num_edges]\n",
    "            where edge_index[0] contains source nodes and edge_index[1] contains \n",
    "            target nodes.\n",
    "        source_indices (list, optional): List of node indices to be considered as \n",
    "            source nodes. Edges originating from these nodes will be assigned type 0,\n",
    "            while all other edges will be assigned type 1. Defaults to [0].\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of shape [num_edges] containing the edge types.\n",
    "            Edges from nodes in source_indices have type 0, others have type 1.\n",
    "    \n",
    "    Example:\n",
    "        >>> edge_index = torch.tensor([[0, 1, 2, 0], [1, 2, 3, 3]])\n",
    "        >>> edge_type = get_edge_type(edge_index, source_indices=[0])\n",
    "        >>> print(edge_type)\n",
    "        tensor([0, 1, 1, 0])\n",
    "    \"\"\"\n",
    "    edge_type = []\n",
    "    for src, tgt in edge_index.t().tolist():\n",
    "        if src in source_indices:\n",
    "            edge_type.append(0)\n",
    "        else:\n",
    "            edge_type.append(1)\n",
    "    return torch.tensor(edge_type)\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "def to_hetero_batch(batch, add_source_self_loop=True):\n",
    "    data_list = batch.to_data_list()\n",
    "    data_list = convert_to_heterogeneous(data_list, 0, add_source_self_loop)\n",
    "    for data in data_list:\n",
    "        print(data)\n",
    "    \n",
    "    batch = Batch.from_data_list(data_list)\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a77d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ModuleList, ReLU, Sequential\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Union, Final\n",
    "\n",
    "from torch_geometric.nn import GATConv, GATv2Conv, HANConv, RGCNConv, global_add_pool, global_mean_pool, global_max_pool\n",
    "from torch_geometric.nn.models.basic_gnn import BasicGNN\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import Adj, OptTensor\n",
    "from torch_geometric.data import HeteroData, Batch\n",
    "\n",
    "\n",
    "#######################\n",
    "# GAT (Graph Attention Network) Models\n",
    "#######################\n",
    "\n",
    "class GAT(BasicGNN):\n",
    "    \"\"\"\n",
    "    Base GAT model that outputs node embeddings.\n",
    "    \"\"\"\n",
    "    supports_edge_weight: Final[bool] = False\n",
    "    supports_edge_attr: Final[bool] = True\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        hidden_channels: int,\n",
    "        out_channels: int,\n",
    "        num_layers: int,\n",
    "        dropout: float = 0.0,\n",
    "        v2: bool = False,\n",
    "        heads: int = 8,\n",
    "        concat: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # Store these attributes before the parent class constructor\n",
    "        self.v2 = v2\n",
    "        self.heads = heads\n",
    "        self.concat = concat\n",
    "        self.out_dim = out_channels\n",
    "        \n",
    "        super().__init__(\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels=hidden_channels,\n",
    "            out_channels=out_channels,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            **kwargs,\n",
    "        )\n",
    "      \n",
    "    def init_conv(self, in_channels: Union[int, Tuple[int, int]],\n",
    "                  out_channels: int, **kwargs) -> MessagePassing:\n",
    "        \n",
    "        # Use the stored attributes\n",
    "        v2 = kwargs.pop('v2', self.v2)\n",
    "        heads = kwargs.pop('heads', self.heads)\n",
    "        concat = kwargs.pop('concat', self.concat)\n",
    "\n",
    "        # Do not use concatenation in case the layer `GATConv` layer maps to\n",
    "        # the desired output channels (out_channels != None and jk != None):\n",
    "        if getattr(self, '_is_conv_to_out', False):\n",
    "            concat = False\n",
    "\n",
    "        if concat and out_channels % heads != 0:\n",
    "            raise ValueError(f\"Ensure that the number of output channels of \"\n",
    "                             f\"'GATConv' (got '{out_channels}') is divisible \"\n",
    "                             f\"by the number of heads (got '{heads}')\")\n",
    "\n",
    "        if concat:\n",
    "            out_channels = out_channels // heads\n",
    "\n",
    "        Conv = GATConv if not v2 else GATv2Conv\n",
    "        return Conv(in_channels, out_channels, heads=heads, concat=concat,\n",
    "                    dropout=self.dropout.p, **kwargs)\n",
    "\n",
    "\n",
    "class GATForGraphClassification(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Graph classification model based on Graph Attention Networks.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        hidden_channels: int,\n",
    "        num_classes: int,\n",
    "        num_layers: int,\n",
    "        dropout: float = 0.0,\n",
    "        pooling: str = 'mean',\n",
    "        v2: bool = False,\n",
    "        heads: int = 8,\n",
    "        concat: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create the base GAT model for node embeddings\n",
    "        self.gat = GAT(\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels=hidden_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            v2=v2,\n",
    "            heads=heads,\n",
    "            concat=concat,\n",
    "            **kwargs,\n",
    "        )\n",
    "        \n",
    "        # Set up the pooling function\n",
    "        if pooling == 'add':\n",
    "            self.pool = global_add_pool\n",
    "        elif pooling == 'mean':\n",
    "            self.pool = global_mean_pool\n",
    "        elif pooling == 'max':\n",
    "            self.pool = global_max_pool\n",
    "        else:\n",
    "            raise ValueError(f\"Pooling type {pooling} not supported.\")\n",
    "        \n",
    "        # Classification layer\n",
    "        self.classifier = Linear(hidden_channels, num_classes)\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Store the embedding dimension for ensemble methods\n",
    "        self.output_dim = hidden_channels\n",
    "      \n",
    "    def forward(self, x, edge_index, batch=None, edge_attr=None):\n",
    "        \"\"\"\n",
    "        Forward pass for graph classification.\n",
    "        \"\"\"\n",
    "        # Get graph embeddings\n",
    "        embeddings = self.get_embedding(x, edge_index, batch, edge_attr)\n",
    "        \n",
    "        # Apply final classification layer\n",
    "        x = F.dropout(embeddings, p=self.dropout, training=self.training)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_embedding(self, x, edge_index, batch=None, edge_attr=None):\n",
    "        \"\"\"\n",
    "        Get graph-level embeddings for use in classification or ensemble methods.\n",
    "        \"\"\"\n",
    "        # Get node embeddings from the base GAT model\n",
    "        x = self.gat(x, edge_index, edge_attr=edge_attr)\n",
    "        \n",
    "        # Pool node features to graph-level representation\n",
    "        if batch is None:\n",
    "            # If no batch is provided, assume a single graph\n",
    "            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "        \n",
    "        # Apply pooling to get graph-level representation\n",
    "        x = self.pool(x, batch)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "#######################\n",
    "# HAN (Heterogeneous Graph Attention Network) Models\n",
    "#######################\n",
    "\n",
    "class HAN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Base Heterogeneous Graph Attention Network (HAN) model that outputs node embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 in_channels: Union[int, Dict[str, int]],\n",
    "                 hidden_channels: int,\n",
    "                 out_channels: int, \n",
    "                 heads: int = 8, \n",
    "                 metadata: Optional[Tuple] = None, \n",
    "                 dropout: float = 0.6,\n",
    "                 num_layers: int = 1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.out_dim = out_channels\n",
    "        \n",
    "        # HANConv does not support multiple layers natively\n",
    "        self.han_conv = HANConv(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=hidden_channels, \n",
    "            heads=heads,\n",
    "            dropout=dropout, \n",
    "            metadata=metadata\n",
    "        )\n",
    "        \n",
    "        # For multi-layer networks, we create additional transformation layers\n",
    "        self.transforms = ModuleList()\n",
    "        if num_layers > 1:\n",
    "            # First transformation after HANConv\n",
    "            self.transforms.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            \n",
    "            # Additional transformation layers if requested\n",
    "            for _ in range(num_layers - 2):\n",
    "                self.transforms.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "        \n",
    "        # Final transformation to output dimension\n",
    "        self.lin = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        \"\"\"\n",
    "        Forward pass that returns node embeddings for each node type.\n",
    "        \"\"\"\n",
    "        # Get node embeddings from HANConv\n",
    "        x = self.han_conv(x_dict, edge_index_dict)\n",
    "        \n",
    "        # Apply additional transformation layers if specified\n",
    "        if self.num_layers > 1:\n",
    "            for i, transform in enumerate(self.transforms):\n",
    "                # Apply transformation to each node type's embeddings\n",
    "                for node_type in x.keys():\n",
    "                    if x[node_type] is not None:\n",
    "                        x[node_type] = transform(x[node_type])\n",
    "                        x[node_type] = F.relu(x[node_type])\n",
    "                        x[node_type] = F.dropout(x[node_type], p=0.5, training=self.training)\n",
    "        \n",
    "        # Apply final linear transformation to each node type's embeddings\n",
    "        for node_type in x.keys():\n",
    "            if x[node_type] is not None:\n",
    "                x[node_type] = self.lin(x[node_type])\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################\n",
    "# RGCN (Relational Graph Convolutional Network) Models\n",
    "#######################\n",
    "\n",
    "class RGCN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Base Relational Graph Convolutional Network (RGCN) model that outputs node embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 in_channels: int, \n",
    "                 hidden_channels: int, \n",
    "                 out_channels: int,\n",
    "                 num_relations: int, \n",
    "                 num_bases: Optional[int] = None,\n",
    "                 num_layers: int = 2,\n",
    "                 dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.out_dim = out_channels\n",
    "        \n",
    "        # Create RGCN layers\n",
    "        self.convs = ModuleList()\n",
    "        \n",
    "        # First layer\n",
    "        self.convs.append(\n",
    "            RGCNConv(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=hidden_channels,\n",
    "                num_relations=num_relations,\n",
    "                num_bases=num_bases\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Middle layers (if any)\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                RGCNConv(\n",
    "                    in_channels=hidden_channels,\n",
    "                    out_channels=hidden_channels,\n",
    "                    num_relations=num_relations,\n",
    "                    num_bases=num_bases\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Last layer\n",
    "        if num_layers > 1:\n",
    "            self.convs.append(\n",
    "                RGCNConv(\n",
    "                    in_channels=hidden_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    num_relations=num_relations,\n",
    "                    num_bases=num_bases\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        \"\"\"\n",
    "        Forward pass that returns node embeddings.\n",
    "        \"\"\"\n",
    "        # Apply RGCN layers\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index, edge_type)\n",
    "            if i < len(self.convs) - 1:  # Apply activation to all but the last layer\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "                \n",
    "        return x\n",
    "\n",
    "\n",
    "class RGCNForGraphClassification(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Graph classification model based on Relational Graph Convolutional Networks.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 in_channels: int, \n",
    "                 hidden_channels: int, \n",
    "                 num_classes: int,\n",
    "                 num_relations: int, \n",
    "                 num_bases: Optional[int] = None,\n",
    "                 num_layers: int = 2,\n",
    "                 dropout: float = 0.5,\n",
    "                 pooling: str = 'mean'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create the base RGCN model for node embeddings\n",
    "        self.rgcn = RGCN(\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels=hidden_channels,\n",
    "            out_channels=hidden_channels,  # Use same dimension for simplicity\n",
    "            num_relations=num_relations,\n",
    "            num_bases=num_bases,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Set up the pooling function\n",
    "        if pooling == 'add':\n",
    "            self.pool = global_add_pool\n",
    "        elif pooling == 'mean':\n",
    "            self.pool = global_mean_pool\n",
    "        elif pooling == 'max':\n",
    "            self.pool = global_max_pool\n",
    "        else:\n",
    "            raise ValueError(f\"Pooling type {pooling} not supported.\")\n",
    "        \n",
    "        # Classification layer\n",
    "        self.classifier = Linear(hidden_channels, num_classes)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Store the embedding dimension for ensemble methods\n",
    "        self.output_dim = hidden_channels\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_type, batch):\n",
    "        \"\"\"\n",
    "        Forward pass for graph classification.\n",
    "        \"\"\"\n",
    "        # Get graph embeddings\n",
    "        embeddings = self.get_embedding(x, edge_index, edge_type, batch)\n",
    "        \n",
    "        # Apply final classifier\n",
    "        x = F.dropout(embeddings, p=self.dropout, training=self.training)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_embedding(self, x, edge_index, edge_type, batch):\n",
    "        \"\"\"\n",
    "        Get graph-level embeddings for use in classification or ensemble methods.\n",
    "        \"\"\"\n",
    "        # Get node embeddings from the base RGCN model\n",
    "        x = self.rgcn(x, edge_index, edge_type)\n",
    "        \n",
    "        # Global pooling (from node-level to graph-level representation)\n",
    "        x = self.pool(x, batch)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "#######################\n",
    "# Ensemble Models\n",
    "#######################\n",
    "\n",
    "class EnsembleGraphClassifier(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Ensemble model that combines multiple graph neural networks for graph classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 models: List[torch.nn.Module],\n",
    "                 ensemble_method: str = 'voting',\n",
    "                 num_classes: int = 2,\n",
    "                 hidden_dim: int = 64,\n",
    "                 dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.models = torch.nn.ModuleList(models)\n",
    "        self.ensemble_method = ensemble_method\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        if ensemble_method == 'concat':\n",
    "            # Calculate total embedding dimension from all models\n",
    "            total_dim = sum(model.output_dim for model in models)\n",
    "            self.classifier = torch.nn.Linear(total_dim, num_classes)\n",
    "            \n",
    "        elif ensemble_method == 'transform':\n",
    "            # Fixed-size hidden layer regardless of number of models\n",
    "            total_dim = sum(model.output_dim for model in models)\n",
    "            self.transform = torch.nn.Linear(total_dim, hidden_dim)\n",
    "            self.classifier = torch.nn.Linear(hidden_dim, num_classes)\n",
    "            \n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Forward pass for ensemble graph classification.\n",
    "        \"\"\"\n",
    "        if self.ensemble_method == 'voting':\n",
    "            # Get logits from each model\n",
    "            all_logits = []\n",
    "            for model in self.models:\n",
    "                if hasattr(model, 'forward_data'):\n",
    "                    # Use specialized data handling if available\n",
    "                    logits = model.forward_data(data)\n",
    "                else:\n",
    "                    # Extract appropriate inputs based on model type\n",
    "                    if isinstance(model, GATForGraphClassification):\n",
    "                        logits = model(data.x, data.edge_index, data.batch, getattr(data, 'edge_attr', None))\n",
    "                    elif isinstance(model, HANForGraphClassification):\n",
    "                        if not isinstance(data, HeteroData):\n",
    "                            data_list = Batch.to_data_list(data)\n",
    "                            data_list = convert_to_heterogeneous(data_list)\n",
    "                            heter_data = Batch.from_data_list(data_list)\n",
    "                        else:\n",
    "                            heter_data = data\n",
    "                        heter_data.to(data.x.device)\n",
    "                        logits = model(heter_data.x_dict, heter_data.edge_index_dict)\n",
    "                    elif isinstance(model, RGCNForGraphClassification):\n",
    "                        # Generate edge_type if not present\n",
    "                        if not hasattr(data, 'edge_type'):\n",
    "                            edge_type = get_edge_type(data.edge_index, \n",
    "                                    source_indices=data.ptr[:-1].tolist() if hasattr(data, 'ptr') else [0])\n",
    "                        else:\n",
    "                            edge_type = data.edge_type\n",
    "                        logits = model(data.x, data.edge_index, edge_type, data.batch)\n",
    "                    else:\n",
    "                        raise TypeError(f\"Unsupported model type: {type(model)}\")\n",
    "                \n",
    "                all_logits.append(logits)\n",
    "            \n",
    "            # For training, we need to return logits, not predictions\n",
    "            # Average the logits from all models\n",
    "            if self.training:\n",
    "                all_logits_stacked = torch.stack(all_logits, dim=0)\n",
    "                return torch.mean(all_logits_stacked, dim=0)\n",
    "            else:\n",
    "                # For evaluation/inference, we can do voting on the predicted classes\n",
    "                all_preds = [torch.argmax(logit, dim=1) for logit in all_logits]\n",
    "                all_preds = torch.stack(all_preds, dim=0)\n",
    "                # Get the most common prediction (mode) for each sample\n",
    "                final_preds_values, _ = torch.mode(all_preds, dim=0)\n",
    "                \n",
    "                # Convert predictions back to one-hot format for consistency\n",
    "                batch_size = final_preds_values.size(0)\n",
    "                final_logits = torch.zeros(batch_size, self.num_classes, device=data.x.device)\n",
    "                for i in range(batch_size):\n",
    "                    final_logits[i, final_preds_values[i]] = 1.0\n",
    "                \n",
    "                return final_logits\n",
    "            \n",
    "        elif self.ensemble_method == 'average':\n",
    "            # Average logits from all models\n",
    "            all_logits = []\n",
    "            for model in self.models:\n",
    "                if hasattr(model, 'forward_data'):\n",
    "                    # Use specialized data handling if available\n",
    "                    logits = model.forward_data(data)\n",
    "                else:\n",
    "                    # Extract appropriate inputs based on model type\n",
    "                    if isinstance(model, GATForGraphClassification):\n",
    "                        logits = model(data.x, data.edge_index, data.batch, getattr(data, 'edge_attr', None))\n",
    "                    elif isinstance(model, HANForGraphClassification):\n",
    "                        if not isinstance(data, HeteroData):\n",
    "                            data_list = Batch.to_data_list(data)\n",
    "                            data_list = convert_to_heterogeneous(data_list)\n",
    "                            heter_data = Batch.from_data_list(data_list)\n",
    "                        else:\n",
    "                            heter_data = data\n",
    "                        heter_data.to(data.x.device)\n",
    "                        logits = model(heter_data.x_dict, heter_data.edge_index_dict)\n",
    "                    elif isinstance(model, RGCNForGraphClassification):\n",
    "                        # Generate edge_type if not present\n",
    "                        if not hasattr(data, 'edge_type'):\n",
    "                            edge_type = get_edge_type(data.edge_index, \n",
    "                                    source_indices=data.ptr[:-1].tolist() if hasattr(data, 'ptr') else [0])\n",
    "                        else:\n",
    "                            edge_type = data.edge_type\n",
    "                        logits = model(data.x, data.edge_index, edge_type, data.batch)\n",
    "                    else:\n",
    "                        raise TypeError(f\"Unsupported model type: {type(model)}\")\n",
    "                \n",
    "                all_logits.append(logits)\n",
    "            \n",
    "            # Stack and average logits\n",
    "            all_logits = torch.stack(all_logits, dim=0)\n",
    "            avg_logits = torch.mean(all_logits, dim=0)\n",
    "            return avg_logits\n",
    "            \n",
    "        elif self.ensemble_method == 'concat' or self.ensemble_method == 'transform':\n",
    "            # Get embeddings from each model\n",
    "            all_embeddings = []\n",
    "            for model in self.models:\n",
    "                if hasattr(model, 'get_embedding_data'):\n",
    "                    # Use specialized data handling if available\n",
    "                    embed = model.get_embedding_data(data)\n",
    "                else:\n",
    "                    # Extract appropriate inputs based on model type\n",
    "                    if isinstance(model, GATForGraphClassification):\n",
    "                        embed = model.get_embedding(data.x, data.edge_index, data.batch, getattr(data, 'edge_attr', None))\n",
    "                    elif isinstance(model, HANForGraphClassification):\n",
    "                        if not isinstance(data, HeteroData):\n",
    "                            data_list = Batch.to_data_list(data)\n",
    "                            data_list = convert_to_heterogeneous(data_list)\n",
    "                            heter_data = Batch.from_data_list(data_list)\n",
    "                        else:\n",
    "                            heter_data = data\n",
    "                        heter_data.to(data.x.device)\n",
    "                        logits = model(heter_data.x_dict, heter_data.edge_index_dict)\n",
    "                    elif isinstance(model, RGCNForGraphClassification):\n",
    "                        # Generate edge_type if not present\n",
    "                        if not hasattr(data, 'edge_type'):\n",
    "                            edge_type = get_edge_type(data.edge_index, \n",
    "                                    source_indices=data.ptr[:-1].tolist() if hasattr(data, 'ptr') else [0])\n",
    "                        else:\n",
    "                            edge_type = data.edge_type\n",
    "                        embed = model.get_embedding(data.x, data.edge_index, edge_type, data.batch)\n",
    "                    else:\n",
    "                        raise TypeError(f\"Unsupported model type: {type(model)}\")\n",
    "                \n",
    "                all_embeddings.append(embed)\n",
    "            \n",
    "            # Concatenate embeddings\n",
    "            combined = torch.cat(all_embeddings, dim=1)\n",
    "            \n",
    "            if self.ensemble_method == 'transform':\n",
    "                combined = F.relu(self.transform(combined))\n",
    "                combined = F.dropout(combined, p=self.dropout, training=self.training)\n",
    "            \n",
    "            # Apply classifier\n",
    "            combined = F.dropout(combined, p=self.dropout, training=self.training)\n",
    "            logits = self.classifier(combined)\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e504e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HANForGraphClassification(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Graph classification model based on Heterogeneous Graph Attention Networks.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 in_channels: Union[int, Dict[str, int]],\n",
    "                 hidden_channels: int,\n",
    "                 out_channels: int, \n",
    "                 num_classes: int = 2,\n",
    "                 heads: int = 8, \n",
    "                 metadata: Optional[Tuple] = None, \n",
    "                 dropout: float = 0.6,\n",
    "                 num_layers: int = 1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create the base HAN model for node embeddings\n",
    "        # The issue is here - you initialize 'self.han', but try to use 'self.han_conv' in forward\n",
    "        # Either rename this to self.han_conv or fix the forward method\n",
    "        self.han_conv = HANConv(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            heads=heads,\n",
    "            dropout=dropout,\n",
    "            metadata=metadata\n",
    "        )\n",
    "        \n",
    "        # Linear layer for dimensionality reduction after pooling\n",
    "        # Will be initialized during forward pass once we know the input dimension\n",
    "        self.lin = None\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        # Classification layer\n",
    "        self.classifier = torch.nn.Linear(out_channels, num_classes)\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Store the embedding dimension for ensemble methods\n",
    "        self.output_dim = out_channels\n",
    "    \n",
    "    def forward(self, x_dict, edge_index_dict, batch=None):\n",
    "        \"\"\"\n",
    "        Forward pass for heterogeneous graph classification.\n",
    "        \"\"\"\n",
    "        # Get node embeddings from HANConv (this line needs to match your initialization)\n",
    "        x = self.get_embedding(x_dict, edge_index_dict, batch)\n",
    "        \n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_embedding(self, x_dict, edge_index_dict, batch=None):\n",
    "        \"\"\"\n",
    "        Get graph-level embeddings for use in classification or ensemble methods.\n",
    "        \"\"\"\n",
    "        # Get node embeddings from the base HAN model\n",
    "        node_embeddings_dict = self.han_conv(x_dict, edge_index_dict)\n",
    "        \n",
    "        # Average pooling for each node type\n",
    "        pooled_embeddings = {}\n",
    "        if batch is None:\n",
    "            # If no batch is provided, assume a single graph\n",
    "            batch = {node_type: torch.zeros(embeddings.size(0), dtype=torch.long, device=embeddings.device)\n",
    "                     for node_type, embeddings in node_embeddings_dict.items() if embeddings is not None}\n",
    "        for node_type, embeddings in node_embeddings_dict.items():\n",
    "            if embeddings is not None:\n",
    "                # Average pooling for nodes of the same type\n",
    "                pooled = global_mean_pool(embeddings, batch[node_type])\n",
    "                pooled_embeddings.setdefault(node_type, []).append(pooled)\n",
    "        \n",
    "        if not pooled_embeddings:\n",
    "            raise ValueError(\"No node embeddings were produced by the model\")\n",
    "        \n",
    "        embeddings_by_batch = []\n",
    "        for source, user in zip(pooled_embeddings['source'], pooled_embeddings['user']):\n",
    "            embeddings_by_batch += (source + user) / 2\n",
    "        # Concatenate all pooled embeddings from different node types\n",
    "        for i,  embed in enumerate(embeddings_by_batch):\n",
    "            print(f\"embed at {i}: {embed.shape}\")\n",
    "        x = torch.stack(embeddings_by_batch, dim=0)\n",
    "        print(f\"Concatenated pooled embeddings shape: {x.shape}\")\n",
    "        # Initialize the linear layer if not done yet\n",
    "        if self.lin is None:\n",
    "            lin_input_dim = x.size(1)\n",
    "            self.lin = torch.nn.Linear(lin_input_dim, self.out_channels).to(x.device)\n",
    "        \n",
    "        # Apply linear layer\n",
    "        x = self.lin(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29f8be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import UPFD\n",
    "# different feature types can be selected: content(profile + spacy; dim: 310), profile(dim: 10), spacy(dim: 300)\n",
    "# splits: train, test, val\n",
    "# name: politifact, gossipcop\n",
    "dataset = UPFD('data/upfd', name=\"politifact\", feature='bert', split=\"train\")\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "# Create a DataLoader for the dataset\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de4587ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "# print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "182b670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  source={\n",
      "    x=[1, 768],\n",
      "    y=[1],\n",
      "  },\n",
      "  user={ x=[84, 768] },\n",
      "  (source, to, user)={ edge_index=[2, 51] },\n",
      "  (user, to, user)={ edge_index=[2, 33] },\n",
      "  (source, to, source)={ edge_index=[2, 1] }\n",
      ")\n",
      "HeteroData(\n",
      "  source={\n",
      "    x=[1, 768],\n",
      "    y=[1],\n",
      "  },\n",
      "  user={ x=[24, 768] },\n",
      "  (source, to, user)={ edge_index=[2, 23] },\n",
      "  (user, to, user)={ edge_index=[2, 1] },\n",
      "  (source, to, source)={ edge_index=[2, 1] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data_list = Batch.to_data_list(batch)\n",
    "hetero_dataset = [\n",
    "    convert_single_graph(graph) \n",
    "    for graph in data_list\n",
    "]\n",
    "\n",
    "for data in hetero_dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82332de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': tensor([0, 1]),\n",
       " 'user': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_hetero_batch(batch, add_source_self_loop=True):\n",
    "    data_list = batch.to_data_list()\n",
    "    data_list = convert_to_heterogeneous(data_list, 0, add_source_self_loop)\n",
    "    batch = Batch.from_data_list(data_list)\n",
    "    batch.batch = {\n",
    "        'source': batch['source'].batch,\n",
    "        'user': batch['user'].batch\n",
    "    }\n",
    "    \n",
    "    return batch\n",
    "hetero_batch = to_hetero_batch(batch)\n",
    "hetero_batch.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "573b4d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([490])\n"
     ]
    }
   ],
   "source": [
    "print(hetero_batch['user'].batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "befa92af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed at 0: torch.Size([64])\n",
      "embed at 1: torch.Size([64])\n",
      "Concatenated pooled embeddings shape: torch.Size([2, 64])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "han_cls = HANForGraphClassification(\n",
    "  in_channels=dataset.num_features,\n",
    "  hidden_channels=64,\n",
    "  out_channels=64,\n",
    "  num_classes=2,\n",
    "  heads=8,\n",
    "  dropout=0.5,\n",
    "  metadata=(['source', 'user'], [('source', 'to', 'user'), ('user', 'to', 'user'), ('source', 'to', 'source')]))\n",
    "\n",
    "\n",
    "# print(hetero_batch)\n",
    "# print(f\"user batch shape: {hetero_batch['user'].batch.shape}\")\n",
    "# print(f\"source batch shape: {hetero_batch['source'].batch.shape}\")\n",
    "out = han_cls(hetero_batch.x_dict, hetero_batch.edge_index_dict, batch=hetero_batch.batch)\n",
    "print(out.shape)\n",
    "# embed = han_cls.get_embedding(hetero_batch.x_dict, hetero_batch.edge_index_dict, batch={'user': hetero_batch['user'].batch, 'source': hetero_batch['source'].batch})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
