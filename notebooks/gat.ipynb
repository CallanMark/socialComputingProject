{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import UPFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different feature types can be selected: content(profile + spacy; dim: 310), profile(dim: 10), spacy(dim: 300)\n",
    "# splits: train, test, val\n",
    "# name: politifact, gossipcop\n",
    "dataset = UPFD('data/upfd', name=\"politifact\", feature='bert', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 62\n",
      "Number of classes: 2\n",
      "Number of features: 768\n",
      "Number of node features: 768\n",
      "Number of edge features: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "print(f\"Number of features: {dataset.num_features}\")\n",
    "print(f\"Number of node features: {dataset.num_node_features}\")\n",
    "print(f\"Number of edge features: {dataset.num_edge_features}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph at index 0: Data(x=[72, 768], edge_index=[2, 71], y=[1])\n",
      "Node features shape: torch.Size([72, 768])\n",
      "Node labels shape: torch.Size([1])\n",
      "Edge index shape: torch.Size([2, 71])\n",
      "Edge index: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  8,  8, 16, 16, 16, 16, 16, 16,\n",
      "         24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
      "         24, 24, 24, 24, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 60],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "         19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
      "         37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "         55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]])\n"
     ]
    }
   ],
   "source": [
    "graph = dataset[0]\n",
    "print(f\"Graph at index 0: {graph}\")\n",
    "print(f\"Node features shape: {graph.x.shape}\")\n",
    "print(f\"Node labels shape: {graph.y.shape}\")\n",
    "\n",
    "print(f\"Edge index shape: {graph.edge_index.shape}\")\n",
    "print(f\"Edge index: {graph.edge_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graph.x:  \n",
    "row 0 of graph.x is the encoded article  \n",
    "row n is the encoded past user tweets for user n  \n",
    "\n",
    "label:  \n",
    "0 = real\n",
    "1 = fake\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train gat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ModuleList, ReLU, Sequential\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Union, Final\n",
    "\n",
    "from torch_geometric.nn import GATConv, GATv2Conv, global_add_pool, global_mean_pool, global_max_pool\n",
    "from torch_geometric.nn.models.basic_gnn import BasicGNN\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import Adj, OptTensor\n",
    "\n",
    "class GATforGraphClassification(BasicGNN):\n",
    "    def __init__(\n",
    "      self,\n",
    "      in_channels: int,\n",
    "      hidden_channels: int,\n",
    "      out_channels: int,\n",
    "      num_layers: int,\n",
    "      heads: int,\n",
    "      dropout: float = 0.0,\n",
    "      pooling: str = 'mean',\n",
    "      **kwargs,\n",
    "    ):\n",
    "      self.out_channels_final = out_channels\n",
    "      \n",
    "      super().__init__(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=None,\n",
    "        hidden_channels=hidden_channels,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "        **kwargs,\n",
    "      )\n",
    "      \n",
    "      self.pooling = pooling\n",
    "      \n",
    "      if pooling == 'add':\n",
    "        self.pool = global_add_pool\n",
    "      elif pooling == 'mean':\n",
    "        self.pool = global_mean_pool\n",
    "      elif pooling == 'max':\n",
    "        self.pool = global_max_pool\n",
    "      else:\n",
    "        raise ValueError(f\"Pooling type {pooling} not supported.\")\n",
    "      \n",
    "      self.classifier = Linear(self.out_channels, self.out_channels_final)\n",
    "      \n",
    "    def init_conv(self, in_channels: Union[int, Tuple[int, int]],\n",
    "                  out_channels: int, **kwargs) -> MessagePassing:\n",
    "\n",
    "        v2 = kwargs.pop('v2', False)\n",
    "        heads = kwargs.pop('heads', 1)\n",
    "        concat = kwargs.pop('concat', True)\n",
    "\n",
    "        # Do not use concatenation in case the layer `GATConv` layer maps to\n",
    "        # the desired output channels (out_channels != None and jk != None):\n",
    "        if getattr(self, '_is_conv_to_out', False):\n",
    "            concat = False\n",
    "\n",
    "        if concat and out_channels % heads != 0:\n",
    "            raise ValueError(f\"Ensure that the number of output channels of \"\n",
    "                             f\"'GATConv' (got '{out_channels}') is divisible \"\n",
    "                             f\"by the number of heads (got '{heads}')\")\n",
    "\n",
    "        if concat:\n",
    "            out_channels = out_channels // heads\n",
    "\n",
    "        Conv = GATConv if not v2 else GATv2Conv\n",
    "        return Conv(in_channels, out_channels, heads=heads, concat=concat,\n",
    "                    dropout=self.dropout.p, **kwargs)\n",
    "      \n",
    "    def forward(self, x, edge_index, batch=None, edge_attr=None):\n",
    "        \"\"\"\n",
    "        Forward pass for graph classification.\n",
    "        \n",
    "        Args:\n",
    "            x: Node features [num_nodes, in_channels]\n",
    "            edge_index: Graph connectivity [2, num_edges]\n",
    "            batch: Batch vector [num_nodes] mapping each node to its graph\n",
    "            edge_attr: Edge features [num_edges, edge_dim] (optional)\n",
    "        \n",
    "        Returns:\n",
    "            Graph classification predictions [batch_size, out_channels_final]\n",
    "        \"\"\"\n",
    "        # Get node embeddings using the GNN layers from the parent class\n",
    "        x = self.convs[0](x, edge_index, edge_attr=edge_attr)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        for i, conv in enumerate(self.convs[1:]):\n",
    "            x = self.dropout(x)\n",
    "            x = conv(x, edge_index, edge_attr=edge_attr)\n",
    "            if i < len(self.convs) - 2:\n",
    "                x = self.act(x)\n",
    "        \n",
    "            \n",
    "        # Pool node features to graph-level representation\n",
    "        if batch is None:\n",
    "            # If no batch is provided, assume a single graph\n",
    "            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "        \n",
    "        # Apply pooling to get graph-level representation\n",
    "        x = self.pool(x, batch)\n",
    "        \n",
    "        # Apply final classification layer\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "gat_model = GATforGraphClassification(\n",
    "    in_channels=dataset.num_features,\n",
    "    hidden_channels=64,\n",
    "    out_channels=2,\n",
    "    num_layers=3,\n",
    "    heads=8,\n",
    "    dropout=0.5,\n",
    "    pooling='mean',\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gat_model = gat_model.to(device)\n",
    "\n",
    "dummy_graph = dataset[0].to(device)\n",
    "dummy_graph.x = dummy_graph.x.to(device)\n",
    "dummy_graph.edge_index = dummy_graph.edge_index.to(device)\n",
    "dummy_graph.edge_attr = dummy_graph.edge_attr.to(device) if dummy_graph.edge_attr is not None else None\n",
    "gat_model.eval()\n",
    "out = gat_model(\n",
    "    x=dummy_graph.x,\n",
    "    edge_index=dummy_graph.edge_index,\n",
    "    batch=dummy_graph.batch,\n",
    "    edge_attr=dummy_graph.edge_attr,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_dataset = UPFD('data/upfd', name='politifact', feature='bert', split='train')\n",
    "val_dataset = UPFD('data/upfd', name='politifact', feature='bert', split='val')\n",
    "test_dataset = UPFD('data/upfd', name='politifact', feature='bert', split='test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.0856\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 2/100, Loss: 0.2887\n",
      "Validation Accuracy: 0.8710\n",
      "Epoch 3/100, Loss: 0.0280\n",
      "Validation Accuracy: 0.7097\n",
      "Epoch 4/100, Loss: 0.0616\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 5/100, Loss: 0.2679\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 6/100, Loss: 0.0335\n",
      "Validation Accuracy: 0.8710\n",
      "Epoch 7/100, Loss: 0.1323\n",
      "Validation Accuracy: 0.8710\n",
      "Epoch 8/100, Loss: 0.0783\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 9/100, Loss: 0.0534\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 10/100, Loss: 0.0710\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 11/100, Loss: 0.0587\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 12/100, Loss: 0.0547\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 13/100, Loss: 0.0947\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 14/100, Loss: 0.0421\n",
      "Validation Accuracy: 0.7742\n",
      "Epoch 15/100, Loss: 0.1004\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 16/100, Loss: 0.0136\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 17/100, Loss: 0.1595\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 18/100, Loss: 0.0355\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 19/100, Loss: 0.0766\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 20/100, Loss: 0.0512\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 21/100, Loss: 0.0295\n",
      "Validation Accuracy: 0.7742\n",
      "Epoch 22/100, Loss: 0.0346\n",
      "Validation Accuracy: 0.7742\n",
      "Epoch 23/100, Loss: 0.0681\n",
      "Validation Accuracy: 0.7742\n",
      "Epoch 24/100, Loss: 0.0298\n",
      "Validation Accuracy: 0.7742\n",
      "Epoch 25/100, Loss: 0.0677\n",
      "Validation Accuracy: 0.7742\n",
      "Epoch 26/100, Loss: 0.0686\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 27/100, Loss: 0.0992\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 28/100, Loss: 0.0034\n",
      "Validation Accuracy: 0.7742\n",
      "Epoch 29/100, Loss: 0.0359\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 30/100, Loss: 0.0129\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 31/100, Loss: 0.0290\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 32/100, Loss: 0.0317\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 33/100, Loss: 0.0247\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 34/100, Loss: 0.0301\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 35/100, Loss: 0.0100\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 36/100, Loss: 0.0481\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 37/100, Loss: 0.0609\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 38/100, Loss: 0.0824\n",
      "Validation Accuracy: 0.7742\n",
      "Epoch 39/100, Loss: 0.1404\n",
      "Validation Accuracy: 0.7742\n",
      "Epoch 40/100, Loss: 0.1060\n",
      "Validation Accuracy: 0.6774\n",
      "Epoch 41/100, Loss: 0.0064\n",
      "Validation Accuracy: 0.7097\n",
      "Epoch 42/100, Loss: 0.0009\n",
      "Validation Accuracy: 0.7097\n",
      "Epoch 43/100, Loss: 0.0632\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 44/100, Loss: 0.0119\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 45/100, Loss: 0.0345\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 46/100, Loss: 0.1841\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 47/100, Loss: 0.0223\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 48/100, Loss: 0.0518\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 49/100, Loss: 0.0709\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 50/100, Loss: 0.0663\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 51/100, Loss: 0.0403\n",
      "Validation Accuracy: 0.8710\n",
      "Epoch 52/100, Loss: 0.1057\n",
      "Validation Accuracy: 0.8710\n",
      "Epoch 53/100, Loss: 0.0451\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 54/100, Loss: 0.0546\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 55/100, Loss: 0.0268\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 56/100, Loss: 0.0092\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 57/100, Loss: 0.0434\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 58/100, Loss: 0.0510\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 59/100, Loss: 0.0423\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 60/100, Loss: 0.0489\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 61/100, Loss: 0.1583\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 62/100, Loss: 0.1091\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 63/100, Loss: 0.0622\n",
      "Validation Accuracy: 0.8710\n",
      "Epoch 64/100, Loss: 0.0625\n",
      "Validation Accuracy: 0.8710\n",
      "Epoch 65/100, Loss: 0.1461\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 66/100, Loss: 0.0562\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 67/100, Loss: 0.0648\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 68/100, Loss: 0.1236\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 69/100, Loss: 0.0764\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 70/100, Loss: 0.0179\n",
      "Validation Accuracy: 0.7419\n",
      "Epoch 71/100, Loss: 0.0831\n",
      "Validation Accuracy: 0.7742\n",
      "Epoch 72/100, Loss: 0.0907\n",
      "Validation Accuracy: 0.8710\n",
      "Epoch 73/100, Loss: 0.0977\n",
      "Validation Accuracy: 0.8710\n",
      "Epoch 74/100, Loss: 0.0182\n",
      "Validation Accuracy: 0.8710\n",
      "Epoch 75/100, Loss: 0.1527\n",
      "Validation Accuracy: 0.8710\n",
      "Epoch 76/100, Loss: 0.0001\n",
      "Validation Accuracy: 0.8710\n",
      "Epoch 77/100, Loss: 0.0200\n",
      "Validation Accuracy: 0.8710\n",
      "Epoch 78/100, Loss: 0.0418\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 79/100, Loss: 0.1133\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 80/100, Loss: 0.0819\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 81/100, Loss: 0.0995\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 82/100, Loss: 0.0367\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 83/100, Loss: 0.0272\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 84/100, Loss: 0.0239\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 85/100, Loss: 0.0218\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 86/100, Loss: 0.0823\n",
      "Validation Accuracy: 0.8387\n",
      "Epoch 87/100, Loss: 0.0204\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 88/100, Loss: 0.0264\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 89/100, Loss: 0.0270\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 90/100, Loss: 0.0921\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 91/100, Loss: 0.0612\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 92/100, Loss: 0.0001\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 93/100, Loss: 0.0907\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 94/100, Loss: 0.0227\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 95/100, Loss: 0.0501\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 96/100, Loss: 0.0507\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 97/100, Loss: 0.0173\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 98/100, Loss: 0.0227\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 99/100, Loss: 0.0718\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch 100/100, Loss: 0.0892\n",
      "Validation Accuracy: 0.8387\n",
      "Test Accuracy: 0.8145\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "import torch.nn.functional as F\n",
    "\n",
    "optimizer = torch.optim.AdamW(gat_model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    gat_model.train()\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = gat_model(batch.x, batch.edge_index, batch.batch, batch.edge_attr)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Validation loop\n",
    "    gat_model.eval()\n",
    "    correct = 0\n",
    "    for batch in val_loader:\n",
    "        batch = batch.to(device)\n",
    "        out = gat_model(batch.x, batch.edge_index, batch.batch, batch.edge_attr)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred == batch.y).sum().item()\n",
    "    accuracy = correct / len(val_loader.dataset)\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "# Test loop\n",
    "gat_model.eval()\n",
    "correct = 0\n",
    "for batch in test_loader:\n",
    "    batch = batch.to(device)\n",
    "    out = gat_model(batch.x, batch.edge_index, batch.batch, batch.edge_attr)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct += (pred == batch.y).sum().item()\n",
    "accuracy = correct / len(test_loader.dataset)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
